{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project - Word Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, you'll create a \"word cloud\" from a text by writing a script.  This script needs to process the text, remove punctuation, ignore case and words that do not contain all alphabets, count the frequencies, and ignore uninteresting or irrelevant words.  A dictionary is the output of the `calculate_frequencies` function.  The `wordcloud` module will then generate the image from your dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are all the installs and imports you will need for your word cloud script and uploader widget\n",
    "\n",
    "from collections import defaultdict\n",
    "import wordcloud\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display\n",
    "import io\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "01fe manh\n01fe17bme068@gmail.com\n1\n1\n1\n1 2 3 give...\n1 also can\n1 excluding u\n1 hour\n1 is giving tra\n"
    }
   ],
   "source": [
    "f = open('C:\\\\Users\\\\gau6r\\\\Downloads\\\\ktk.txt',encoding=\"utf8\")\n",
    "file_contents = f.read()\n",
    "f.close()\n",
    "print(file_contents[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The uploader widget saved the contents of your uploaded file into a string object named *file_contents* that your word cloud script can process. This was a lot of preliminary work, but you are now ready to begin your script. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function in the cell below that iterates through the words in *file_contents*, removes punctuation, and counts the frequency of each word.  Oh, and be sure to make it ignore word case, words that do not contain all alphabets and boring words like \"and\" or \"the\".  Then use it in the `generate_from_frequencies` function to generate your very own word cloud!\n",
    "<br><br>\n",
    "**Hint:** Try storing the results of your iteration in a dictionary before passing them into wordcloud via the `generate_from_frequencies` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_frequencies(file_contents):\n",
    "    # Here is a list of punctuations and uninteresting words you can use to process your text\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    uninteresting_words = [\"the\", \"a\", \"to\", \"if\", \"is\", \"it\", \"of\", \"and\", \"or\", \"an\", \"as\", \"i\", \"me\", \"my\", \\\n",
    "    \"we\", \"our\", \"ours\", \"you\", \"your\", \"yours\", \"he\", \"she\", \"him\", \"his\", \"her\", \"hers\", \"its\", \"they\", \"them\", \\\n",
    "    \"their\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"am\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \\\n",
    "    \"have\", \"has\", \"had\", \"do\", \"does\", \"did\", \"but\", \"at\", \"by\", \"with\", \"from\", \"here\", \"when\", \"where\", \"how\", \\\n",
    "    \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"some\", \"such\", \"no\", \"nor\", \"too\", \"very\", \"can\", \"will\", \"just\",\"hmm\",\"hm\"]\n",
    "    \n",
    "    # LEARNER CODE START HERE\n",
    "    file_contents=file_contents.casefold()\n",
    "    res=\"\"\n",
    "    myd=defaultdict(int)\n",
    "    for i in file_contents:\n",
    "        if i not in punctuations:\n",
    "            if i=='\\n':\n",
    "                res+=' '\n",
    "            else:\n",
    "                res+=i\n",
    "    for i in res.split():\n",
    "        if i not in uninteresting_words and i.isalnum():\n",
    "            myd[i]+=1\n",
    "    #wordcloud\n",
    "    cloud = wordcloud.WordCloud(width=2000, height=2000,max_words=1000,background_color='white')\n",
    "    cloud.generate_from_frequencies(myd)\n",
    "    cloud.to_file(os.path.join(os.getcwd(),\"ktk.png\"))\n",
    "    return cloud.to_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1192\n136\n48\n"
    }
   ],
   "source": [
    "# Display your wordcloud image\n",
    "myimage = calculate_frequencies(file_contents)"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-crash-course",
   "graded_item_id": "Z5d28",
   "launcher_item_id": "eSjyd"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}